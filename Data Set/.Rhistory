# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/File Management & Database/7330-Term-Porject/Data Set")
library(tidyverse)
# text mining library
library(tidytext)
vis_dat(tweets)
#plotting and pipes
library(ggplot2)
#Look at data
library(visdat)
# Look at missing Data
library(naniar)
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
tweets %>% select(user_name,user_location,user_city,user_country,user_state)
tweets %>% select(user_location,user_city,user_country,user_state)
# Decide to fix USA after fixing STATES name first
usa.states = read_csv("usa_states.csv")
usa.states = data.frame(usa.states)
usa.states$State = toupper(usa.states$State)
usa.states = usa.states[,-2]
head(usa.states)
usstatelength = dim(usa.states)[1]
tweetslength
tweetslength = dim(tweets)[1] #4139
tweetslength
tweets[1,17]
tweets[1,18]
usstatelength = dim(usa.states)[1]
tweets %>% select(user_location,user_city,user_country,user_state)
temp =tweets %>% select(user_location,user_city,user_country,user_state)
is.na(temp[1,19])
is.na(temp[1,18])
head(temp)
is.na(temp[1,14])
is.na(temp[1,4])
usa.states[1,2]
dim(tweets)
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
if(grepl(usa.states[j,2],tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
current.state = usa.states[j,2]
paste(" ","hello")
paste("","hello")
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
# Fixing user_state where country is United States with only city name and State Code
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
current.state = paste("",usa.states[j,2])
if(grepl(current.state,tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
paste(" ","AL","^",sep = "")
# Fixing user_state where country is United States with only city name and State Code
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
current.state = paste(" ",usa.states[j,2],"^",sep = "")
if(grepl(current.state,tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
tweets%>%select(user_location,user_country,user_state)
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
# Fixing user_state where country is United States with only city name and State Code
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
current.state = paste(" ",usa.states[j,2],"$",sep = "")
if(grepl(current.state,tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
# Fixing user_state where country is United States with only city name and State Code
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
current.state = paste(usa.states[j,2],"$",sep = "")
if(grepl(current.state,tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
# Fixing user_state where country is United States with only city name and State Code
for(i in 1:tweetslength){
if((!is.na(tweets[i,18]))&grepl("UNITED STATES",tweets[i,18])&is.na(tweets[i,19])){
for(j in 1:usstatelength){
current.state = paste(" ",usa.states[j,2],"$",sep = "")
if(grepl(current.state,tweets[i,3])){
print(paste("fixing tweet",i))
tweets[i,19]=usa.states[j,1]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,18]))
break
}
}
}
}
#Adding state code
tweets$us_state_code= as.character(NA)
str(tweets)
tweets[1,19]
tweets[1,20]
#Adding USA state code for easier merging data.
for(i in 1:tweetslength){
if(!is.na(tweets[i,19])){
for(j in 1:usstatelength){
if(usa.states[j,1]==tweets[i,19]){
print(paste("fixing tweet",i))
tweets[i,20]=usa.states[j,2]
print(paste("fixed",tweets[i,3],tweets[i,19],tweets[i,20]))
break
}
}
}
}
###########################################################################################
#another write out
write.csv(tweets,"fixed_location_tweets4.csv",row.names=FALSE)
tweets = read_csv("fixed_location_tweets4.csv")
tweets = data.frame(tweets)
str(tweets)
# Look at missing data
gg_miss_var(tweets)
# Look at TOP US STATES
tweets %>%
count(user_state,sort = TRUE) %>%
mutate(user_state = reorder(user_state, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_state,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique State")
# Look at TOP WORLD CITIES
tweets %>%
count(user_city,sort = TRUE) %>%
mutate(user_city = reorder(user_city, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_city,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique City")
# Look at TOP Countries
tweets %>%
count(user_country,sort = TRUE) %>%
mutate(user_country = reorder(user_country, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_country,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique Country")
tweets = read_csv("fixed_location_tweets3.csv")
tweets = data.frame(tweets)
# Look at missing data
gg_miss_var(tweets)
# Look at TOP US STATES
tweets %>%
count(user_state,sort = TRUE) %>%
mutate(user_state = reorder(user_state, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_state,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique State")
# Look at TOP Countries
tweets %>%
count(user_country,sort = TRUE) %>%
mutate(user_country = reorder(user_country, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_country,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique Country")
# Look at TOP WORLD CITIES
tweets %>%
count(user_city,sort = TRUE) %>%
mutate(user_city = reorder(user_city, n)) %>%
na.omit()%>%
top_n(20)%>%
ggplot(aes(x=user_city,y=n))+
geom_col()+
coord_flip()+
labs(x = "Count",y="Location",title="Where Twitter users are from - unique City")
