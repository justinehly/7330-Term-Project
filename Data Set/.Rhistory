# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/File Management & Database/7330-Term-Porject/Data Set")
library(tidyverse)
# text mining library
library(tidytext)
vis_dat(tweets)
#plotting and pipes
library(ggplot2)
tweets = read_csv("fixed_location_tweets4.csv")
tweets = data.frame(tweets)
#Look at data
library(visdat)
# Look at missing Data
library(naniar)
########################################################################################
# Do some regex operation to get rid of urls and "\n" or "\r" new lines under text field
# Text processing - create function to remove url and new line in text
########################################################################################
#Reference: https://stackoverflow.com/questions/42460803/regex-in-r-remove-multiple-urls-from-string
clean_text = function(string){
#Remove URL
string = gsub("\\s?(f|ht)(tp)(s?)(://)([^\\.]*)[\\.|/](\\S*)","", string)
#Remove \r and \n
string = gsub("\r?\n|\r"," ",string)
return(string)
}
# Performance regex on tweets$text column
tweets$text = clean_text(tweets$text)
# Uniform Date Format
library(lubridate)
tweets$date = ymd_hms(tweets$date)
# Write just tweets comments column out to a csv
write.csv(tweets$text, "tweet_posts.csv", row.names=F)
tweet1 = read.csv("tweet_posts.csv",header = FALSE)
dim(tweet1)
# Load the package required to read JSON files.
library("rjson")
library(jsonlite)
# Give the input file name to the function.
result <- stream_in(file("sentiment_0218.json"))
# Print the result.
head(result)
result$Sentiment
head(tweets)
# Convert JSON file to a data frame.
json_data_frame <- as.data.frame(result)
print(json_data_frame)
dim(json_data_frame)
tail(json_data_frame,5)
# Create new sentiment data frame frome extracting from json_data_frame
sentiment.col = json_data_frame$Sentiment
# Create new sentiment data frame frome extracting from json_data_frame
sentiment = json_data_frame$Sentiment
sentimentScore.mixed = json_data_frame$SentimentScore$Mixed
sentimentScore.negative = json_data_frame$SentimentScore$Negative
sentimentScore.neutral = json_data_frame$SentimentScore$Neutral
sentimentScore.positive = json_data_frame$SentimentScore$Positive
df = data.frame(sentiment,sentimentScore.mixed,sentimentScore.negative,sentimentScore.neutral,sentimentScore.positive)
dim(df)
head(df)
tail(tweets,2)
# Create new sentiment data frame frome extracting from json_data_frame
tweets$sentiment = json_data_frame$Sentiment
tweets$sentimentScore.mixed = json_data_frame$SentimentScore$Mixed
tweets$sentimentScore.negative = json_data_frame$SentimentScore$Negative
tweets$sentimentScore.neutral = json_data_frame$SentimentScore$Neutral
tweets$sentimentScore.positive = json_data_frame$SentimentScore$Positive
str(tweets)
compare = tweets%>% select(text,sentiment)
head(compare,5)
tail(compare,5)
head(compare,5)
###########################################################################################
#another write out
write.csv(tweets,"tweets_loc_sen0223.csv",row.names=FALSE)
# You need to adjust the work environment to run this code
setwd("/Users/mingyang/Desktop/SMU/File Management & Database/7330-Term-Porject/Data Set")
library(tidyverse)
#plotting and pipes
library(ggplot2)
# text mining library
library(tidytext)
#Look at data
library(visdat)
vis_dat(tweets)
# Look at missing Data
library(naniar)
tweets = read_csv("tweets_loc_sen0223.csv")
tweets = data.frame(tweets)
# Look at missing data
gg_miss_var(tweets)
# Look at structure of tweets
str(tweets)
dim(tweets)
